{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33657,"databundleVersionId":3279164,"sourceType":"competition"}],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ikram98ai/us-patent-phrase-to-phrase-matching?scriptVersionId=189685936\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Import and EDA","metadata":{}},{"cell_type":"code","source":"# %pip install -U datasets==2.17.0\n# %pip install transformers==4.27.2 ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datasets import Dataset,DatasetDict\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\nfrom transformers import TrainingArguments,Trainer","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:55:41.186475Z","iopub.execute_input":"2024-07-25T06:55:41.187239Z","iopub.status.idle":"2024-07-25T06:55:41.191653Z","shell.execute_reply.started":"2024-07-25T06:55:41.187193Z","shell.execute_reply":"2024-07-25T06:55:41.19084Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.249714Z","iopub.execute_input":"2024-07-25T06:34:05.249941Z","iopub.status.idle":"2024-07-25T06:34:05.340065Z","shell.execute_reply.started":"2024-07-25T06:34:05.249914Z","shell.execute_reply":"2024-07-25T06:34:05.339342Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                     id        anchor                  target context  score\n0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n...                 ...           ...                     ...     ...    ...\n36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n36471  756ec035e694722b  wood article         wooden material     B44   0.75\n36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n\n[36473 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37d61fd2272659b1</td>\n      <td>abatement</td>\n      <td>abatement of pollution</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b9652b17b68b7a4</td>\n      <td>abatement</td>\n      <td>act of abating</td>\n      <td>A47</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36d72442aefd8232</td>\n      <td>abatement</td>\n      <td>active catalyst</td>\n      <td>A47</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5296b0c19e1ce60e</td>\n      <td>abatement</td>\n      <td>eliminating process</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54c1e3b9184cb5b6</td>\n      <td>abatement</td>\n      <td>forest region</td>\n      <td>A47</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36468</th>\n      <td>8e1386cbefd7f245</td>\n      <td>wood article</td>\n      <td>wooden article</td>\n      <td>B44</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>36469</th>\n      <td>42d9e032d1cd3242</td>\n      <td>wood article</td>\n      <td>wooden box</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36470</th>\n      <td>208654ccb9e14fa3</td>\n      <td>wood article</td>\n      <td>wooden handle</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36471</th>\n      <td>756ec035e694722b</td>\n      <td>wood article</td>\n      <td>wooden material</td>\n      <td>B44</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>36472</th>\n      <td>8d135da0b55b8c88</td>\n      <td>wood article</td>\n      <td>wooden substrate</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>36473 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.341492Z","iopub.execute_input":"2024-07-25T06:34:05.341737Z","iopub.status.idle":"2024-07-25T06:34:05.546254Z","shell.execute_reply.started":"2024-07-25T06:34:05.341708Z","shell.execute_reply":"2024-07-25T06:34:05.545524Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                      id                       anchor       target context\ncount              36473                        36473        36473   36473\nunique             36473                          733        29340     106\ntop     37d61fd2272659b1  component composite coating  composition     H01\nfreq                   1                          152           24    2186","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36473</td>\n      <td>733</td>\n      <td>29340</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>37d61fd2272659b1</td>\n      <td>component composite coating</td>\n      <td>composition</td>\n      <td>H01</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>152</td>\n      <td>24</td>\n      <td>2186</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.score.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.547533Z","iopub.execute_input":"2024-07-25T06:34:05.547832Z","iopub.status.idle":"2024-07-25T06:34:05.558591Z","shell.execute_reply.started":"2024-07-25T06:34:05.547791Z","shell.execute_reply":"2024-07-25T06:34:05.557705Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"count    36473.000000\nmean         0.362062\nstd          0.258335\nmin          0.000000\n25%          0.250000\n50%          0.250000\n75%          0.500000\nmax          1.000000\nName: score, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"df.score.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.560761Z","iopub.execute_input":"2024-07-25T06:34:05.561371Z","iopub.status.idle":"2024-07-25T06:34:05.569061Z","shell.execute_reply.started":"2024-07-25T06:34:05.561328Z","shell.execute_reply":"2024-07-25T06:34:05.5682Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0.50    12300\n0.25    11519\n0.00     7471\n0.75     4029\n1.00     1154\nName: score, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.score.value_counts(normalize=True).round(3)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.570264Z","iopub.execute_input":"2024-07-25T06:34:05.570573Z","iopub.status.idle":"2024-07-25T06:34:05.583125Z","shell.execute_reply.started":"2024-07-25T06:34:05.570532Z","shell.execute_reply":"2024-07-25T06:34:05.582366Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0.50    0.337\n0.25    0.316\n0.00    0.205\n0.75    0.110\n1.00    0.032\nName: score, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.584138Z","iopub.execute_input":"2024-07-25T06:34:05.584367Z","iopub.status.idle":"2024-07-25T06:34:05.61907Z","shell.execute_reply.started":"2024-07-25T06:34:05.584334Z","shell.execute_reply":"2024-07-25T06:34:05.618441Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(max([len(input_text) for input_text in df.input]))\nprint(min([len(input_text) for input_text in df.input]))","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.620053Z","iopub.execute_input":"2024-07-25T06:34:05.620257Z","iopub.status.idle":"2024-07-25T06:34:05.640679Z","shell.execute_reply.started":"2024-07-25T06:34:05.620234Z","shell.execute_reply":"2024-07-25T06:34:05.639937Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"133\n33\n","output_type":"stream"}]},{"cell_type":"code","source":"df.input.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.641683Z","iopub.execute_input":"2024-07-25T06:34:05.641925Z","iopub.status.idle":"2024-07-25T06:34:05.65363Z","shell.execute_reply.started":"2024-07-25T06:34:05.641897Z","shell.execute_reply":"2024-07-25T06:34:05.652855Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0    TEXT1: A47; TEXT2: abatement of pollution; ANC...\n1    TEXT1: A47; TEXT2: act of abating; ANC1: abate...\n2    TEXT1: A47; TEXT2: active catalyst; ANC1: abat...\n3    TEXT1: A47; TEXT2: eliminating process; ANC1: ...\n4    TEXT1: A47; TEXT2: forest region; ANC1: abatement\nName: input, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"ds = Dataset.from_pandas(df)\nds","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.655952Z","iopub.execute_input":"2024-07-25T06:34:05.656326Z","iopub.status.idle":"2024-07-25T06:34:05.684006Z","shell.execute_reply.started":"2024-07-25T06:34:05.656257Z","shell.execute_reply":"2024-07-25T06:34:05.683308Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n    num_rows: 36473\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"A deep learning model expects numbers as inputs, not English sentences! So we need to do two things:\n\n- *Tokenization*: Split each text up into words (or actually, as we'll see, into *tokens*)\n- *Numericalization*: Convert each word (or token) into a number.","metadata":{}},{"cell_type":"code","source":"model_nm = 'microsoft/deberta-v3-small'","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.684875Z","iopub.execute_input":"2024-07-25T06:34:05.685051Z","iopub.status.idle":"2024-07-25T06:34:05.688606Z","shell.execute_reply.started":"2024-07-25T06:34:05.685028Z","shell.execute_reply":"2024-07-25T06:34:05.687885Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# `AutoTokenizer` will create a tokenizer appropriate for a given model:\ntokz = AutoTokenizer.from_pretrained(model_nm)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:05.68972Z","iopub.execute_input":"2024-07-25T06:34:05.689953Z","iopub.status.idle":"2024-07-25T06:34:07.595556Z","shell.execute_reply.started":"2024-07-25T06:34:05.689924Z","shell.execute_reply":"2024-07-25T06:34:07.594743Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Uncommon words will be split into pieces. The start of a new word is represented by `▁`:\nprint(tokz.tokenize(\"A platypus is an ornithorhynchus anatinus.\"))","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:07.59686Z","iopub.execute_input":"2024-07-25T06:34:07.597159Z","iopub.status.idle":"2024-07-25T06:34:07.601849Z","shell.execute_reply.started":"2024-07-25T06:34:07.597111Z","shell.execute_reply":"2024-07-25T06:34:07.60114Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"['▁A', '▁platypus', '▁is', '▁an', '▁or', 'ni', 'tho', 'rhynch', 'us', '▁an', 'at', 'inus', '.']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Here's a simple function which tokenizes our inputs:\ndef tok_func(x): return tokz(x[\"input\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:07.60288Z","iopub.execute_input":"2024-07-25T06:34:07.603087Z","iopub.status.idle":"2024-07-25T06:34:07.612856Z","shell.execute_reply.started":"2024-07-25T06:34:07.603062Z","shell.execute_reply":"2024-07-25T06:34:07.612156Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# To run this quickly in parallel on every row in our dataset, use map\ntok_ds = ds.map(tok_func, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:07.613886Z","iopub.execute_input":"2024-07-25T06:34:07.614453Z","iopub.status.idle":"2024-07-25T06:34:16.072361Z","shell.execute_reply.started":"2024-07-25T06:34:07.614421Z","shell.execute_reply":"2024-07-25T06:34:16.071736Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/37 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43b0d7406a8242aab622f764b9e56ac9"}},"metadata":{}}]},{"cell_type":"code","source":"#  the input and IDs for the first row of our data:\nrow = tok_ds[0]\nprint(row['input'])\nprint(row['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:16.07497Z","iopub.execute_input":"2024-07-25T06:34:16.07546Z","iopub.status.idle":"2024-07-25T06:34:16.080362Z","shell.execute_reply.started":"2024-07-25T06:34:16.075418Z","shell.execute_reply":"2024-07-25T06:34:16.079598Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement\n[1, 54453, 435, 294, 336, 5753, 346, 54453, 445, 294, 47284, 265, 6435, 346, 23702, 435, 294, 47284, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Vocab in the tokenizer which contains a unique integer for every possible token string\ntokz.vocab['▁of']","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:16.081446Z","iopub.execute_input":"2024-07-25T06:34:16.082115Z","iopub.status.idle":"2024-07-25T06:34:16.0939Z","shell.execute_reply.started":"2024-07-25T06:34:16.082075Z","shell.execute_reply":"2024-07-25T06:34:16.093029Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"265"},"metadata":{}}]},{"cell_type":"code","source":"# Transformers always assumes that your labels has the column name `labels`, it's currently `score`.\ntok_ds = tok_ds.rename_columns({'score':'labels'})","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:34:16.095058Z","iopub.execute_input":"2024-07-25T06:34:16.095394Z","iopub.status.idle":"2024-07-25T06:34:16.106773Z","shell.execute_reply.started":"2024-07-25T06:34:16.095357Z","shell.execute_reply":"2024-07-25T06:34:16.106123Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## train test split","metadata":{}},{"cell_type":"code","source":"dds = tok_ds.train_test_split(0.25, seed=42)\ndds","metadata":{"hidden":true,"execution":{"iopub.status.busy":"2024-07-25T06:37:09.842183Z","iopub.execute_input":"2024-07-25T06:37:09.842824Z","iopub.status.idle":"2024-07-25T06:37:09.866971Z","shell.execute_reply.started":"2024-07-25T06:37:09.842787Z","shell.execute_reply":"2024-07-25T06:37:09.866239Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27354\n    })\n    test: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9119\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Metrics and correlation","metadata":{"heading_collapsed":true}},{"cell_type":"markdown","source":"*submissions are evaluated on the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) between the predicted and actual similarity scores*. This coefficient is usually abbreviated using the single letter *r*. It is the most widely used measure of the degree of relationship between two variables.\n","metadata":{"hidden":true}},{"cell_type":"code","source":"def corr(x,y): return np.corrcoef(x,y)[0][1]","metadata":{"hidden":true,"execution":{"iopub.status.busy":"2024-07-25T06:43:42.401609Z","iopub.execute_input":"2024-07-25T06:43:42.40244Z","iopub.status.idle":"2024-07-25T06:43:42.406599Z","shell.execute_reply.started":"2024-07-25T06:43:42.4024Z","shell.execute_reply":"2024-07-25T06:43:42.405703Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def show_corr(df, a, b):\n    x,y = df[a],df[b]\n    plt.scatter(x,y, alpha=0.5, s=4)\n    plt.title(f'{a} vs {b}; r: {corr(x, y):.2f}')","metadata":{"hidden":true,"execution":{"iopub.status.busy":"2024-07-25T06:43:42.81535Z","iopub.execute_input":"2024-07-25T06:43:42.815622Z","iopub.status.idle":"2024-07-25T06:43:42.82025Z","shell.execute_reply.started":"2024-07-25T06:43:42.815588Z","shell.execute_reply":"2024-07-25T06:43:42.819477Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Transformers expects metrics to be returned as a `dict`, so the trainer knows what label to use.\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}","metadata":{"hidden":true,"execution":{"iopub.status.busy":"2024-07-25T06:43:44.015537Z","iopub.execute_input":"2024-07-25T06:43:44.015823Z","iopub.status.idle":"2024-07-25T06:43:44.019878Z","shell.execute_reply.started":"2024-07-25T06:43:44.015792Z","shell.execute_reply":"2024-07-25T06:43:44.019096Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Training our model","metadata":{}},{"cell_type":"code","source":"# We pick a batch size that fits our GPU, and small number of epochs so we can run experiments quickly\nbs = 128\nepochs = 4\nlr = 8e-5","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:46:19.01844Z","iopub.execute_input":"2024-07-25T06:46:19.01907Z","iopub.status.idle":"2024-07-25T06:46:19.02307Z","shell.execute_reply.started":"2024-07-25T06:46:19.01903Z","shell.execute_reply":"2024-07-25T06:46:19.022288Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Transformers uses the `TrainingArguments` class to set up arguments\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:46:19.394042Z","iopub.execute_input":"2024-07-25T06:46:19.394608Z","iopub.status.idle":"2024-07-25T06:46:19.452992Z","shell.execute_reply.started":"2024-07-25T06:46:19.39457Z","shell.execute_reply":"2024-07-25T06:46:19.452258Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n# Trainer is a class which combines the data and model together\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokz, compute_metrics=corr_d)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:47:11.339841Z","iopub.execute_input":"2024-07-25T06:47:11.340544Z","iopub.status.idle":"2024-07-25T06:47:24.724269Z","shell.execute_reply.started":"2024-07-25T06:47:11.34051Z","shell.execute_reply":"2024-07-25T06:47:24.723598Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/273M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a5388f9b054cacb23821ac7a503edc"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias']\n- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing amp half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train();","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:47:27.988943Z","iopub.execute_input":"2024-07-25T06:47:27.989196Z","iopub.status.idle":"2024-07-25T06:52:26.2275Z","shell.execute_reply.started":"2024-07-25T06:47:27.98917Z","shell.execute_reply":"2024-07-25T06:52:26.22679Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"The following columns in the training set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, input, target, anchor.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 27354\n  Num Epochs = 4\n  Instantaneous batch size per device = 128\n  Total train batch size (w. parallel, distributed & accumulation) = 128\n  Gradient Accumulation steps = 1\n  Total optimization steps = 856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [856/856 04:56, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.026180</td>\n      <td>0.796731</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.022060</td>\n      <td>0.822574</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.033400</td>\n      <td>0.022044</td>\n      <td>0.833279</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.033400</td>\n      <td>0.022786</td>\n      <td>0.833725</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/trainer.py:1410: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  args.max_grad_norm,\nThe following columns in the evaluation set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, input, target, anchor.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 256\nThe following columns in the evaluation set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, input, target, anchor.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 256\nSaving model checkpoint to outputs/checkpoint-500\nConfiguration saved in outputs/checkpoint-500/config.json\nModel weights saved in outputs/checkpoint-500/pytorch_model.bin\ntokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in outputs/checkpoint-500/special_tokens_map.json\nadded tokens file saved in outputs/checkpoint-500/added_tokens.json\nThe following columns in the evaluation set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, input, target, anchor.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 256\nThe following columns in the evaluation set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, input, target, anchor.\n***** Running Evaluation *****\n  Num examples = 9119\n  Batch size = 256\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The key thing to look at is the \"Pearson\" value in table above. As you see, it's increasing, and is already above 0.8. That's great news!","metadata":{}},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"actual = np.array(dds['test']['labels'])\neval_ds = dds['test'].remove_columns('labels')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs = peft_trainer.predict(eval_ds).predictions.astype(float)\n# Initialize an array of zeros with the same shape as probs\npreds = np.zeros_like(probs)\n\n# # Use np.argmax to find the index of the max value in each row\n# max_indices = np.argmax(probs, axis=1)\n# preds[np.arange(preds.shape[0]), max_indices] = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(corr_d([actual,preds]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test set","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv')\ntest_df['input'] = 'TEXT1: ' + test_df.context + '; TEXT2: ' + test_df.target + '; ANC1: ' + test_df.anchor\ntest_ds = Dataset.from_pandas(test_df).map(tok_func, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:53:16.565043Z","iopub.execute_input":"2024-07-25T06:53:16.565702Z","iopub.status.idle":"2024-07-25T06:53:17.934971Z","shell.execute_reply.started":"2024-07-25T06:53:16.565658Z","shell.execute_reply":"2024-07-25T06:53:17.93428Z"},"trusted":true},"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc61db0013c0496bb80f323874baa3ec"}},"metadata":{}}]},{"cell_type":"code","source":"preds = trainer.predict(test_ds).predictions.astype(float)\npreds","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:53:19.510043Z","iopub.execute_input":"2024-07-25T06:53:19.510588Z","iopub.status.idle":"2024-07-25T06:53:19.564672Z","shell.execute_reply.started":"2024-07-25T06:53:19.510554Z","shell.execute_reply":"2024-07-25T06:53:19.563959Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, id, target, input, anchor.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 256\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"array([[ 0.56103516],\n       [ 0.67480469],\n       [ 0.53857422],\n       [ 0.32128906],\n       [-0.00606918],\n       [ 0.54150391],\n       [ 0.5078125 ],\n       [ 0.05545044],\n       [ 0.26025391],\n       [ 1.12011719],\n       [ 0.26000977],\n       [ 0.23596191],\n       [ 0.72509766],\n       [ 0.87548828],\n       [ 0.71533203],\n       [ 0.50292969],\n       [ 0.34008789],\n       [-0.02651978],\n       [ 0.64404297],\n       [ 0.37426758],\n       [ 0.48803711],\n       [ 0.26855469],\n       [ 0.08905029],\n       [ 0.28857422],\n       [ 0.58789062],\n       [-0.02453613],\n       [-0.03347778],\n       [-0.0295105 ],\n       [-0.03665161],\n       [ 0.51416016],\n       [ 0.34008789],\n       [ 0.02220154],\n       [ 0.75      ],\n       [ 0.50341797],\n       [ 0.44604492],\n       [ 0.22900391]])"},"metadata":{}}]},{"cell_type":"code","source":"# some of our predictions are <0, or >1!  fixing those out-of-bounds predictions:\npreds = np.clip(preds, 0, 1)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:53:27.123056Z","iopub.execute_input":"2024-07-25T06:53:27.123575Z","iopub.status.idle":"2024-07-25T06:53:27.127453Z","shell.execute_reply.started":"2024-07-25T06:53:27.123542Z","shell.execute_reply":"2024-07-25T06:53:27.12664Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"preds.round(2)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:56:09.841344Z","iopub.execute_input":"2024-07-25T06:56:09.842131Z","iopub.status.idle":"2024-07-25T06:56:09.848213Z","shell.execute_reply.started":"2024-07-25T06:56:09.842093Z","shell.execute_reply":"2024-07-25T06:56:09.847517Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"array([[0.56],\n       [0.67],\n       [0.54],\n       [0.32],\n       [0.  ],\n       [0.54],\n       [0.51],\n       [0.06],\n       [0.26],\n       [1.  ],\n       [0.26],\n       [0.24],\n       [0.73],\n       [0.88],\n       [0.72],\n       [0.5 ],\n       [0.34],\n       [0.  ],\n       [0.64],\n       [0.37],\n       [0.49],\n       [0.27],\n       [0.09],\n       [0.29],\n       [0.59],\n       [0.  ],\n       [0.  ],\n       [0.  ],\n       [0.  ],\n       [0.51],\n       [0.34],\n       [0.02],\n       [0.75],\n       [0.5 ],\n       [0.45],\n       [0.23]])"},"metadata":{}}]},{"cell_type":"code","source":"# Save a CSV in notebook\nsubmission = Dataset.from_dict({\n    'id': test_ds['id'],\n    'score': preds\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T06:56:23.397853Z","iopub.execute_input":"2024-07-25T06:56:23.398462Z","iopub.status.idle":"2024-07-25T06:56:23.454312Z","shell.execute_reply.started":"2024-07-25T06:56:23.398424Z","shell.execute_reply":"2024-07-25T06:56:23.453609Z"},"trusted":true},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"693072532b5b48a6ba624da70f9db82e"}},"metadata":{}},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"1026"},"metadata":{}}]}]}