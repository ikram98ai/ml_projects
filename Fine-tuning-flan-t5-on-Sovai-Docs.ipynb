{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9079852,"sourceType":"datasetVersion","datasetId":5477832}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install peft loralib evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:39:47.724319Z","iopub.execute_input":"2024-08-01T12:39:47.724963Z","iopub.status.idle":"2024-08-01T12:40:05.052262Z","shell.execute_reply.started":"2024-08-01T12:39:47.724934Z","shell.execute_reply":"2024-08-01T12:40:05.051084Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nCollecting loralib\n  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.4)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.20.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=543376192d6e1f3b18bb1c091e28a02a7fcc87c9fb3e4a8e718759f6af329381\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: loralib, rouge_score, peft, evaluate\nSuccessfully installed evaluate-0.4.2 loralib-0.1.2 peft-0.12.0 rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport torch,os,gc\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\nimport datasets\nfrom datasets import Dataset,DatasetDict\nimport evaluate\nrouge = evaluate.load('rouge')\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-01T12:40:22.186227Z","iopub.execute_input":"2024-08-01T12:40:22.186926Z","iopub.status.idle":"2024-08-01T12:40:23.401003Z","shell.execute_reply.started":"2024-08-01T12:40:22.186897Z","shell.execute_reply":"2024-08-01T12:40:23.400144Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Login with your Hugging Face token\nlogin(\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:41:00.806492Z","iopub.execute_input":"2024-08-01T12:41:00.807673Z","iopub.status.idle":"2024-08-01T12:41:01.068459Z","shell.execute_reply.started":"2024-08-01T12:41:00.807638Z","shell.execute_reply":"2024-08-01T12:41:01.067576Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Loading Data** ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/code-prompts/code_prompts_balanced.csv',sep=';').drop('Unnamed: 0',axis=1).rename(columns={'value':'prompt'})\ndf","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:40:23.403675Z","iopub.execute_input":"2024-08-01T12:40:23.404034Z","iopub.status.idle":"2024-08-01T12:40:23.450435Z","shell.execute_reply.started":"2024-08-01T12:40:23.404000Z","shell.execute_reply":"2024-08-01T12:40:23.449107Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                   code  \\\n0                           sov.data('wikipedia/views')   \n1                           sov.data('corprisk/events')   \n2                       sov.data('factors/alternative')   \n3     sov.data('news/daily', start_date='2017-03-30'...   \n4                       sov.data('factors/alternative')   \n...                                                 ...   \n1021                  sov.data('corprisk/misstatement')   \n1022                                  sov.data('risks')   \n1023                        sov.data('lobbying/public')   \n1024                  sov.data('factors/model_metrics')   \n1025                     sov.data('bankruptcy/monthly')   \n\n                                                 prompt  \n0           retrieve comprehensive Wikipedia views data  \n1               Retrieve data on corporate risk events.  \n2                     Obtain alternative factor details  \n3                 fetch news data for specified tickers  \n4              Fetch data on alternative market factors  \n...                                                 ...  \n1021               Access misstatement risk information  \n1022              Access comprehensive risk information  \n1023  Analyze lobbying efforts by companies or indus...  \n1024               fetch detailed model metrics records  \n1025             Analyze monthly bankruptcy information  \n\n[1026 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sov.data('wikipedia/views')</td>\n      <td>retrieve comprehensive Wikipedia views data</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sov.data('corprisk/events')</td>\n      <td>Retrieve data on corporate risk events.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sov.data('factors/alternative')</td>\n      <td>Obtain alternative factor details</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sov.data('news/daily', start_date='2017-03-30'...</td>\n      <td>fetch news data for specified tickers</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sov.data('factors/alternative')</td>\n      <td>Fetch data on alternative market factors</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1021</th>\n      <td>sov.data('corprisk/misstatement')</td>\n      <td>Access misstatement risk information</td>\n    </tr>\n    <tr>\n      <th>1022</th>\n      <td>sov.data('risks')</td>\n      <td>Access comprehensive risk information</td>\n    </tr>\n    <tr>\n      <th>1023</th>\n      <td>sov.data('lobbying/public')</td>\n      <td>Analyze lobbying efforts by companies or indus...</td>\n    </tr>\n    <tr>\n      <th>1024</th>\n      <td>sov.data('factors/model_metrics')</td>\n      <td>fetch detailed model metrics records</td>\n    </tr>\n    <tr>\n      <th>1025</th>\n      <td>sov.data('bankruptcy/monthly')</td>\n      <td>Analyze monthly bankruptcy information</td>\n    </tr>\n  </tbody>\n</table>\n<p>1026 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"max(df.code.apply(lambda x : len(x.split(' ')))),max(df.prompt.apply(lambda x : len(x.split(' '))))","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:40:23.451796Z","iopub.execute_input":"2024-08-01T12:40:23.452208Z","iopub.status.idle":"2024-08-01T12:40:23.464476Z","shell.execute_reply.started":"2024-08-01T12:40:23.452171Z","shell.execute_reply":"2024-08-01T12:40:23.463290Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(4, 13)"},"metadata":{}}]},{"cell_type":"code","source":"ds = Dataset.from_pandas(df)\n# Define the train-test-validation split ratios\ntrain_test_split = ds.train_test_split(train_size=0.8)\ntest_val_split = train_test_split['test'].train_test_split(test_size=0.2)\n\n# Combine splits to get train, validation, and test datasets\ntrain_ds = train_test_split['train']\nval_ds = test_val_split['train']\ntest_ds = test_val_split['test']\nds=DatasetDict({'train':train_ds,'test':val_ds})\nds,test_ds\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:40:23.465985Z","iopub.execute_input":"2024-08-01T12:40:23.466406Z","iopub.status.idle":"2024-08-01T12:40:23.530068Z","shell.execute_reply.started":"2024-08-01T12:40:23.466366Z","shell.execute_reply":"2024-08-01T12:40:23.528985Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(DatasetDict({\n     train: Dataset({\n         features: ['code', 'prompt'],\n         num_rows: 820\n     })\n     test: Dataset({\n         features: ['code', 'prompt'],\n         num_rows: 164\n     })\n }),\n Dataset({\n     features: ['code', 'prompt'],\n     num_rows: 42\n }))"},"metadata":{}}]},{"cell_type":"markdown","source":"### **Loading Model**","metadata":{}},{"cell_type":"code","source":"model_name = 'google/flan-t5-base'\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)#,torch_dtype=torch.bfloat16)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:42:58.774644Z","iopub.execute_input":"2024-08-01T12:42:58.775018Z","iopub.status.idle":"2024-08-01T12:43:59.930317Z","shell.execute_reply.started":"2024-08-01T12:42:58.774987Z","shell.execute_reply":"2024-08-01T12:43:59.929254Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"360c4aef74bd4c1285dc5c9b41ccf808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78fca1bfa2314ba8a2628a9d528bd77e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f9e47c6a534f4daf94fb6482cdb23a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"702a09cd95c841c1bba5f1e114ff9221"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf25647f50024dd7bd4d461072a8a931"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c69676bd2c7c48999c66cb68975b6cf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e969e499558242dfb9326df0bb630cc6"}},"metadata":{}}]},{"cell_type":"code","source":"def print_trainable_model_params(model):\n    train_model_params= 0\n    all_model_params=0\n    for _,param in model.named_parameters():\n        all_model_params+= param.numel()\n        if param.requires_grad:\n            train_model_params+= param.numel()\n    print(f'All model parameters:{all_model_params/1_000_000:.2f}m, Trainable model parameters:{train_model_params/1_000_000:.2f}m \\nPercentage of trainable parameters:{train_model_params/all_model_params*100}%')\n\nprint_trainable_model_params(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:43:59.932078Z","iopub.execute_input":"2024-08-01T12:43:59.932404Z","iopub.status.idle":"2024-08-01T12:43:59.941383Z","shell.execute_reply.started":"2024-08-01T12:43:59.932377Z","shell.execute_reply":"2024-08-01T12:43:59.940343Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"All model parameters:247.58m, Trainable model parameters:247.58m \nPercentage of trainable parameters:100.0%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Tokenizing Text** ","metadata":{}},{"cell_type":"code","source":"start_prompt = 'Change Text to CODE:\\n\\nTEXT:'\nend_prompt = \"\\n\\nCODE:\"\ndef tokenize_fn(row):\n    prompts = [start_prompt + prompt + end_prompt for prompt in row['prompt']]\n    row['input_ids'] = tokenizer(prompts,padding='max_length',max_length=64,truncation=True,return_tensors='pt').input_ids\n    row['labels'] =tokenizer(row['code'],padding='max_length',max_length=32,truncation=True,return_tensors='pt').input_ids\n    return row ","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:43:59.942515Z","iopub.execute_input":"2024-08-01T12:43:59.942836Z","iopub.status.idle":"2024-08-01T12:43:59.952943Z","shell.execute_reply.started":"2024-08-01T12:43:59.942810Z","shell.execute_reply":"2024-08-01T12:43:59.952038Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tok_ds = ds.map(tokenize_fn,batched=True)\ntok_ds = tok_ds.remove_columns(['code','prompt'])\ntok_ds","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:43:59.955581Z","iopub.execute_input":"2024-08-01T12:43:59.955947Z","iopub.status.idle":"2024-08-01T12:44:00.183941Z","shell.execute_reply.started":"2024-08-01T12:43:59.955922Z","shell.execute_reply":"2024-08-01T12:44:00.182946Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/820 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3215bea1f8b4e768905dea2d73a4f3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/164 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bccc43f560743fd8ab8479826b073a8"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'labels'],\n        num_rows: 820\n    })\n    test: Dataset({\n        features: ['input_ids', 'labels'],\n        num_rows: 164\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### **Training Model** ","metadata":{}},{"cell_type":"code","source":"# training_args = TrainingArguments(\n#     output_dir='.',\n#     learning_rate=1e-5, \n#     num_train_epochs=5,\n#     weight_decay=0.01, \n#     logging_steps=10, \n#     max_steps=100,\n#     evaluation_strategy=\"steps\",\n#     report_to='none'\n# )\n\nbs = 8\nepochs = 4\nlr = 1e-5\n\ntraining_args =TrainingArguments('.', learning_rate=lr, warmup_ratio=0.1, fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n\ntrainer = Trainer(\n    model=model, \n    args=training_args, \n    train_dataset=tok_ds['train'],\n    eval_dataset=tok_ds['test']\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:44:12.661703Z","iopub.execute_input":"2024-08-01T12:44:12.662093Z","iopub.status.idle":"2024-08-01T12:44:13.193456Z","shell.execute_reply.started":"2024-08-01T12:44:12.662063Z","shell.execute_reply":"2024-08-01T12:44:13.192385Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"%%time\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:44:16.522210Z","iopub.execute_input":"2024-08-01T12:44:16.523337Z","iopub.status.idle":"2024-08-01T12:46:03.991763Z","shell.execute_reply.started":"2024-08-01T12:44:16.523293Z","shell.execute_reply":"2024-08-01T12:46:03.990897Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='208' max='208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [208/208 01:44, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>11.889028</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>3.920129</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>2.849373</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>2.551565</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"CPU times: user 2min 5s, sys: 7.93 s, total: 2min 13s\nWall time: 1min 47s\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=208, training_loss=8.346281198354868, metrics={'train_runtime': 106.9839, 'train_samples_per_second': 30.659, 'train_steps_per_second': 1.944, 'total_flos': 280750514503680.0, 'train_loss': 8.346281198354868, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:46:03.993253Z","iopub.execute_input":"2024-08-01T12:46:03.993604Z","iopub.status.idle":"2024-08-01T12:46:04.480650Z","shell.execute_reply.started":"2024-08-01T12:46:03.993575Z","shell.execute_reply":"2024-08-01T12:46:04.479651Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### **Model Evaluation** ","metadata":{}},{"cell_type":"code","source":"instruct_model = AutoModelForSeq2SeqLM.from_pretrained('/kaggle/working/checkpoint-208',torch_dtype=torch.bfloat16)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:47:04.634964Z","iopub.execute_input":"2024-08-01T12:47:04.635808Z","iopub.status.idle":"2024-08-01T12:47:06.644217Z","shell.execute_reply.started":"2024-08-01T12:47:04.635775Z","shell.execute_reply":"2024-08-01T12:47:06.643442Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"list(zip(test_ds['prompt'][:2],test_ds['code'][:2]))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:47:06.645706Z","iopub.execute_input":"2024-08-01T12:47:06.645996Z","iopub.status.idle":"2024-08-01T12:47:06.653697Z","shell.execute_reply.started":"2024-08-01T12:47:06.645971Z","shell.execute_reply":"2024-08-01T12:47:06.652836Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[('Fetch breakout signal activity by date',\n  \"sov.data('breakout').set_index('date')\"),\n ('retrieve movie box office performance data',\n  \"sov.data('movies/boxoffice')\")]"},"metadata":{}}]},{"cell_type":"code","source":"model_codes = []\nfor prompt in test_ds['prompt']:\n    prompt = start_prompt + prompt + end_prompt   \n    input_ids = tokenizer(prompt,return_tensors='pt').input_ids\n    model_code = instruct_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_token=32))\n    model_codes.append(tokenizer.decode(model_code[0],skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:47:22.001812Z","iopub.execute_input":"2024-08-01T12:47:22.002616Z","iopub.status.idle":"2024-08-01T12:47:47.602749Z","shell.execute_reply.started":"2024-08-01T12:47:22.002583Z","shell.execute_reply":"2024-08-01T12:47:47.601546Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"list(zip(test_ds['code'][:5],model_codes[:5]))","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:47:47.604652Z","iopub.execute_input":"2024-08-01T12:47:47.605005Z","iopub.status.idle":"2024-08-01T12:47:47.613087Z","shell.execute_reply.started":"2024-08-01T12:47:47.604978Z","shell.execute_reply":"2024-08-01T12:47:47.612161Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[(\"sov.data('breakout').set_index('date')\",\n  'TEXT:Fetch breakout signal activity by date'),\n (\"sov.data('movies/boxoffice')\",\n  'retrieve movie box office performance data'),\n (\"sov.data('lobbying/public', tickers=['WFC', 'EXPGY'])\",\n  'GET LOCATION INFORMATION FOR WFC AND EXPGY'),\n (\"sov.data('institutional/trading', start_date='2004-04-30', tickers=['MSFT'])\",\n  'TEXT:retrieve institutional trades for MSFT from 2004'),\n (\"sov.data('spending/compensation')\",\n  'TEXT:fetch detailed spending compensation records')]"},"metadata":{}}]},{"cell_type":"code","source":"model_results = rouge.compute(\n    predictions=model_codes,\n    references=test_ds['code'],\n    use_aggregator=True,\n    use_stemmer=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:47:47.614139Z","iopub.execute_input":"2024-08-01T12:47:47.614456Z","iopub.status.idle":"2024-08-01T12:47:47.878502Z","shell.execute_reply.started":"2024-08-01T12:47:47.614391Z","shell.execute_reply":"2024-08-01T12:47:47.877334Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(model_name,\": \",model_results)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:55:44.249360Z","iopub.execute_input":"2024-08-01T12:55:44.250062Z","iopub.status.idle":"2024-08-01T12:55:44.254961Z","shell.execute_reply.started":"2024-08-01T12:55:44.250027Z","shell.execute_reply":"2024-08-01T12:55:44.253896Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"google/flan-t5-base :  {'rouge1': 0.44081063742717863, 'rouge2': 0.07038289674844297, 'rougeL': 0.32232716421128627, 'rougeLsum': 0.32243378437540315}\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_evaluate(model_name,bs=32,lr=1e-5,epochs=4):\n    print('Loading pretrained model and tokenizer...')\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)#,torch_dtype=torch.bfloat16)\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    print_trainable_model_params(model)\n    \n    print('\\nTokenizing text...')\n    def tokenize_fn(row):\n        prompts = [start_prompt + prompt + end_prompt for prompt in row['prompt']]\n        row['input_ids'] = tokenizer(prompts,padding='max_length',max_length=64,truncation=True,return_tensors='pt').input_ids\n        row['labels'] =tokenizer(row['code'],padding='max_length',max_length=32,truncation=True,return_tensors='pt').input_ids\n        return row \n    tok_ds = ds.map(tokenize_fn,batched=True)\n    \n    print('\\nFine-tuning model...')\n    training_args =TrainingArguments(model_name, learning_rate=lr, warmup_ratio=0.1, fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n    trainer = Trainer(\n        model=model, \n        args=training_args, \n        train_dataset=tok_ds['train'],\n        eval_dataset=tok_ds['test']\n    )\n    trainer.train()\n    \n    print('\\nModel evaluation...')\n    out_dir= '/kaggle/working/'+model_name\n    checkpoints = [os.path.join(out_dir, d) for d in os.listdir(out_dir) if d.startswith('checkpoint')]\n    instruct_model = AutoModelForSeq2SeqLM.from_pretrained(checkpoints[0],torch_dtype=torch.bfloat16)\n    model_codes = []\n    for prompt in test_ds['prompt']:\n        prompt = start_prompt + prompt + end_prompt   \n        input_ids = tokenizer(prompt,return_tensors='pt').input_ids\n        model_code = instruct_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_token=32))\n        model_codes.append(tokenizer.decode(model_code[0],skip_special_tokens=True))\n    print(list(zip(test_ds['code'][:3],model_codes[:3])))\n    model_results = rouge.compute(\n    predictions=model_codes,\n    references=test_ds['code'],\n    use_aggregator=True,\n    use_stemmer=True )\n    print(model_name,\": \",model_results)\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:50:00.539829Z","iopub.execute_input":"2024-08-01T12:50:00.540506Z","iopub.status.idle":"2024-08-01T12:50:00.554032Z","shell.execute_reply.started":"2024-08-01T12:50:00.540475Z","shell.execute_reply":"2024-08-01T12:50:00.552948Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}